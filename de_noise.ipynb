{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network I have been using has similar structure like auto-encoder. Instead of using just a few layers of full connection linear structure, this new network uses convolution layers and pooling layers to extract feature then uses up-pooling layers and de-convolution layers to restore resolution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_ = tf.placeholder(tf.float32, [None, 24, 24, 1])\n",
    "targets_ = tf.placeholder(tf.float32, [None, 24, 24, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part extracting feature is similar to the structure being used in image classification problems. There are three blocks in this part, each part is consist of one convolution layer and one pooling layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = tf.layers.conv2d(inputs_, 64, (3,3), padding='same', activation=tf.nn.relu)\n",
    "conv1 = tf.layers.max_pooling2d(conv1, (2,2), (2,2), padding='same')\n",
    "conv1 = batch_norm(conv1,64)\n",
    "conv2 = tf.layers.conv2d(conv1, 64, (3,3), padding='same', activation=tf.nn.relu)\n",
    "conv2 = tf.layers.max_pooling2d(conv2, (2,2), (2,2), padding='same')\n",
    "conv2 = batch_norm(conv2,64)\n",
    "conv3 = tf.layers.conv2d(conv2, 32, (3,3), padding='same', activation=tf.nn.relu)\n",
    "conv3 = tf.layers.max_pooling2d(conv3, (2,2), (2,2), padding='same')\n",
    "conv3 = batch_norm(conv3,32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added a batch normalization layer to the end of every block to avoid over fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(Wx_plus_b,out_size):\n",
    "    fc_mean, fc_var = tf.nn.moments(\n",
    "        Wx_plus_b,\n",
    "        axes=[0],  # the dimension you wanna normalize, here [0] for batch\n",
    "        # for image, you wanna do [0, 1, 2] for [batch, height, width] but not channel\n",
    "    )\n",
    "    scale = tf.Variable(tf.ones([out_size]))\n",
    "    shift = tf.Variable(tf.zeros([out_size]))\n",
    "    epsilon = 0.001\n",
    "    # apply moving average for mean and var when train on batch\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "    def mean_var_with_update():\n",
    "        ema_apply_op = ema.apply([fc_mean, fc_var])\n",
    "        with tf.control_dependencies([ema_apply_op]):\n",
    "            return tf.identity(fc_mean), tf.identity(fc_var)\n",
    "    mean, var = mean_var_with_update()\n",
    "    Wx_plus_b = tf.nn.batch_normalization(Wx_plus_b, mean, var, shift, scale, epsilon)\n",
    "    return Wx_plus_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part is up-pooling and de-convolution layer. This part is symmetrical to the first part to restore the resolution of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv4 = tf.image.resize_nearest_neighbor(conv3, (6,6))\n",
    "conv4 = tf.layers.conv2d(conv4, 32, (3,3), padding='same', activation=tf.nn.relu)\n",
    "conv4 = batch_norm(conv4,32)\n",
    "conv5 = tf.image.resize_nearest_neighbor(conv4, (12,12))\n",
    "conv5 = tf.layers.conv2d(conv5, 64, (3,3), padding='same', activation=tf.nn.relu)\n",
    "conv5 = batch_norm(conv5,64)\n",
    "conv6 = tf.image.resize_nearest_neighbor(conv5, (24,24))\n",
    "conv6 = tf.layers.conv2d(conv6, 64, (3,3), padding='same', activation=tf.nn.relu)\n",
    "conv6 = batch_norm(conv6,64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.image.resize_nearest_neighbor is a function build in tensorflow to resize `images` to `size` using nearest neighbor interpolation. It is the reverse operation of pooling. The de-convolution layer is still using convolution but have the symmetric structure as corresponding convolution layer. For example, the third convolution layer take tensor with shape [10,6,6,64] and get tensor with shape [10,6,6,32]; the fifth layer is the symmetrical de-convolution layer which take tensor with shape [10,6,6,32] and get tensor with shape [10,6,6,64]. (the tensorâ€™s shape is [batch_size, length, width, filters])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, in the end if going symmetrically the outputs should have the same shape as the input US image, but I made it two feature maps instead of one. By doing this, softmax function can be applied to the last dimension to decide if one pixel should be bright or dark. In this way, the result will be more clear than just use sigmoid or relu as activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_ = tf.layers.conv2d(conv6, 2, (3,3), padding='same', activation=None)\n",
    "outputs_ = tf.nn.softmax(logits_, dim= -1,name='outputs_')\n",
    "outputs_ = outputs_[:,:,:,0]\n",
    "outputs_ = tf.reshape(outputs_ , [-1,24,24,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function I choose the Euclid distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(tf.reshape(targets_,[-1]) - tf.reshape(outputs_,[-1])))\n",
    "optimizer = tf.train.AdamOptimizer(0.0005).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the full code and result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import scipy.signal as signal\n",
    "\n",
    "def add_noise(img,n=1000):\n",
    "    rows, cols = np.shape(img)\n",
    "    for i in range(n):\n",
    "        x = np.random.randint(0, rows)\n",
    "        y = np.random.randint(0, cols)\n",
    "        img[x, y] = 255\n",
    "    return np.array(img)\n",
    "\n",
    "def func(x,y,sigma=1):\n",
    "    return 100*(1/(2*np.pi*sigma))*np.exp(-((x-2)**2+(y-2)**2)/(2.0*sigma**2))\n",
    "\n",
    "def add_gauss_noise(image,r=10):\n",
    "    suanzi = np.fromfunction(func, (r, r), sigma=5)\n",
    "    image = np.array(image)\n",
    "    image2 = signal.convolve2d(image, suanzi, mode=\"same\")\n",
    "    image2 = (image2 / float(image2.max())) * 255\n",
    "    return np.array(image2)\n",
    "\n",
    "def gray2binary(a):\n",
    "    for i in range(len(a)):\n",
    "        if a[i]>60:\n",
    "            a[i]=1\n",
    "        elif a[i]<=60:\n",
    "            a[i]=0\n",
    "    return a\n",
    "\n",
    "def get_train_batch(noise=500):\n",
    "    ran = np.random.randint(600,5800,size=10,dtype='int')\n",
    "    image = []\n",
    "    label = []\n",
    "    n_pic = ran\n",
    "    for i in range(10):\n",
    "        frame_0 = cv2.imread('./cropedoriginalUS2/%d.jpg' % (n_pic[i]), 0)\n",
    "        #frame_0 = add_noise(frame_0, n = noise)\n",
    "        frame_0 = cv2.resize(frame_0, (24, 24))\n",
    "        frame_0 = np.array(frame_0).reshape(-1)\n",
    "        frame_0 = frame_0 / 255.0\n",
    "        image.append(frame_0)\n",
    "        #print(np.shape(image))\n",
    "    for i in range(10):\n",
    "        frame_1 = cv2.imread('./cropedoriginalPixel2/%d.jpg' % (n_pic[i]), 0)\n",
    "        frame_1 = cv2.resize(frame_1, (24, 24))\n",
    "        frame_1 = np.array(frame_1).reshape(-1)\n",
    "        frame_1 = gray2binary(frame_1)\n",
    "        label.append(frame_1)\n",
    "    return np.array(image,dtype='float') , np.array(label,dtype='float')\n",
    "\n",
    "def get_test_batch(noise=500):\n",
    "    ran = np.random.randint(5800,6000,size=10,dtype='int')\n",
    "    image = []\n",
    "    label = []\n",
    "    n_pic = ran\n",
    "    for i in range(10):\n",
    "        frame_0 = cv2.imread('./cropedoriginalUS2/%d.jpg' % (n_pic[i]), 0)\n",
    "        #frame_0 = add_noise(frame_0, n = noise)\n",
    "        frame_0 = cv2.resize(frame_0, (24, 24))\n",
    "        frame_0 = np.array(frame_0).reshape(-1)\n",
    "        frame_0 = frame_0 / 255.0\n",
    "        image.append(frame_0)\n",
    "    for i in range(10):\n",
    "        frame_1 = cv2.imread('./cropedoriginalPixel2/%d.jpg' % (n_pic[i]), 0)\n",
    "        frame_1 = cv2.resize(frame_1, (24, 24))\n",
    "        frame_1 = np.array(frame_1).reshape(-1)\n",
    "        frame_1 = gray2binary(frame_1)\n",
    "        label.append(frame_1)\n",
    "    return np.array(image,dtype='float') , np.array(label,dtype='float')\n",
    "\n",
    "def batch_norm(Wx_plus_b,out_size):\n",
    "    fc_mean, fc_var = tf.nn.moments(\n",
    "        Wx_plus_b,\n",
    "        axes=[0],  # the dimension you wanna normalize, here [0] for batch\n",
    "        # for image, you wanna do [0, 1, 2] for [batch, height, width] but not channel\n",
    "    )\n",
    "    scale = tf.Variable(tf.ones([out_size]))\n",
    "    shift = tf.Variable(tf.zeros([out_size]))\n",
    "    epsilon = 0.001\n",
    "    # apply moving average for mean and var when train on batch\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "    def mean_var_with_update():\n",
    "        ema_apply_op = ema.apply([fc_mean, fc_var])\n",
    "        with tf.control_dependencies([ema_apply_op]):\n",
    "            return tf.identity(fc_mean), tf.identity(fc_var)\n",
    "    mean, var = mean_var_with_update()\n",
    "    Wx_plus_b = tf.nn.batch_normalization(Wx_plus_b, mean, var, shift, scale, epsilon)\n",
    "    return Wx_plus_b\n",
    "\n",
    "inputs_ = tf.placeholder(tf.float32, [None, 24, 24, 1])\n",
    "targets_ = tf.placeholder(tf.float32, [None, 24, 24, 1])\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs_, 64, (3,3), padding='same', activation=tf.nn.relu)\n",
    "conv1 = tf.layers.max_pooling2d(conv1, (2,2), (2,2), padding='same')\n",
    "conv1 = batch_norm(conv1,64)\n",
    "conv2 = tf.layers.conv2d(conv1, 64, (3,3), padding='same', activation=tf.nn.relu)\n",
    "conv2 = tf.layers.max_pooling2d(conv2, (2,2), (2,2), padding='same')\n",
    "conv2 = batch_norm(conv2,64)\n",
    "conv3 = tf.layers.conv2d(conv2, 32, (3,3), padding='same', activation=tf.nn.relu)\n",
    "conv3 = tf.layers.max_pooling2d(conv3, (2,2), (2,2), padding='same')\n",
    "conv3 = batch_norm(conv3,32)\n",
    "conv4 = tf.image.resize_nearest_neighbor(conv3, (6,6))\n",
    "conv4 = tf.layers.conv2d(conv4, 32, (3,3), padding='same', activation=tf.nn.relu)\n",
    "conv4 = batch_norm(conv4,32)\n",
    "conv5 = tf.image.resize_nearest_neighbor(conv4, (12,12))\n",
    "conv5 = tf.layers.conv2d(conv5, 64, (3,3), padding='same', activation=tf.nn.relu)\n",
    "conv5 = batch_norm(conv5,64)\n",
    "conv6 = tf.image.resize_nearest_neighbor(conv5, (24,24))\n",
    "conv6 = tf.layers.conv2d(conv6, 64, (3,3), padding='same', activation=tf.nn.relu)\n",
    "conv6 = batch_norm(conv6,64)\n",
    "logits_ = tf.layers.conv2d(conv6, 2, (3,3), padding='same', activation=None)\n",
    "outputs_ = tf.nn.softmax(logits_, dim= -1,name='outputs_')\n",
    "outputs_ = outputs_[:,:,:,0]\n",
    "outputs_ = tf.reshape(outputs_ , [-1,24,24,1])\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(tf.reshape(targets_,[-1]) - tf.reshape(outputs_,[-1])))\n",
    "# loss = tf.nn.softmax_cross_entropy_with_logits(labels=targets_, logits=outputs_)\n",
    "# cost = tf.reduce_mean(loss)\n",
    "optimizer = tf.train.AdamOptimizer(0.0005).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    for i in range(10000):\n",
    "        batch, img = get_train_batch()\n",
    "        batch= np.reshape(batch,[-1, 24, 24, 1])\n",
    "        img= np.reshape(img,[-1, 24, 24, 1])\n",
    "        sess.run(optimizer, feed_dict={inputs_: batch, targets_: img})\n",
    "        if i % 200 == 0:\n",
    "            batch_cost = sess.run(cost, feed_dict={inputs_: batch, targets_: img})\n",
    "            print(\"Batch: {} \".format(i), \"Training loss: {:.4f}\".format(batch_cost))\n",
    "    print(\"Optimization Finishes!\")\n",
    "\n",
    "    batch_xs, batch_ys = get_test_batch()\n",
    "    batch_xs = np.reshape(batch_xs,[-1, 24, 24, 1])\n",
    "    batch_ys = np.reshape(batch_ys, [-1, 24, 24, 1])\n",
    "    image_p = sess.run(outputs_, feed_dict={inputs_: batch_xs, targets_: batch_ys})\n",
    "    # image_p = gray2binary(image_p)\n",
    "\n",
    "    f, a = plt.subplots(3, 10, figsize=(10, 3))\n",
    "    for i in range(10):\n",
    "        #a[0][i].imshow(np.reshape(ys_0[i], (LONGITUDE, LONGITUDE)))\n",
    "        a[0][i].imshow(np.reshape(batch_ys[i], (24, 24)))\n",
    "        a[1][i].imshow(np.reshape(batch_xs[i], (24, 24)))\n",
    "        a[2][i].imshow(np.reshape(image_p[i], (24, 24)))\n",
    "\n",
    "        # a[3][i].imshow(np.reshape(gray2binary(image_p[i]), (LONGITUDE, LONGITUDE)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "img1=cv2.imread('./result/loss.png')\n",
    "img2=cv2.imread('./result/de-conv lr=0.0005 train=10000 noise US activation=softmax stucture=123-321.png')\n",
    "plt.figure(1)\n",
    "plt.imshow(img1)\n",
    "plt.figure(2)\n",
    "plt.imshow(img2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}